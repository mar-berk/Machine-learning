{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook, we will predict the character of lines of dialogue from the *Simpsons*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing ##\n",
    "\n",
    "\n",
    "First, let's start with the code to generate a document-feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Bart Simpson</td>\n",
       "      <td>Victory party under the slide!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Mr. Bergstrom! Mr. Bergstrom!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Do you know where I could find him?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_character_text                         spoken_words\n",
       "1        Lisa Simpson               Where's Mr. Bergstrom?\n",
       "3        Lisa Simpson           That life is worth living.\n",
       "7        Bart Simpson       Victory party under the slide!\n",
       "9        Lisa Simpson        Mr. Bergstrom! Mr. Bergstrom!\n",
       "11       Lisa Simpson  Do you know where I could find him?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('simpsons.csv')\n",
    "df = df.loc[(df['raw_character_text'] == 'Lisa Simpson') | (df['raw_character_text'] == 'Bart Simpson')]\n",
    "text = df['spoken_words'].values.astype('U') #Taking the text from the df. We need to convert it to Unicode\n",
    "vect = CountVectorizer(stop_words='english') #Create the CV object, with English stop words\n",
    "vect = vect.fit(text) #We fit the model with the words from the review text\n",
    "docu_feat = vect.transform(text) # make a matrix\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model ##\n",
    "\n",
    "Now, we will use the Na√Øve Bayes classifier from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB() #create the model\n",
    "X = docu_feat #the document-feature matrix is the X matrix\n",
    "y = df['raw_character_text'] #creating the y vector\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) #split the data and store it\n",
    "\n",
    "nb = nb.fit(X_train, y_train) #fit the model X=features, y=character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6323432343234323"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Evaluate the model\n",
    "y_test_p = nb.predict(X_test)\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 63.7%, which is not great considering there are only two categories. What if we guessed the same category all the time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bart Simpson    0.544954\n",
       "Lisa Simpson    0.455046\n",
       "Name: raw_character_text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['raw_character_text'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're doing about 9.3 percentage points better than when we guessed Bart all the time. Not great, but that's to be expected with such short lines of dialogue. Let's create a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bart pred</th>\n",
       "      <th>Lisa pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Bart</td>\n",
       "      <td>3251</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Lisa</td>\n",
       "      <td>1881</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bart pred  Lisa pred\n",
       "Bart       3251        904\n",
       "Lisa       1881       1539"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_test_p)\n",
    "cm = pd.DataFrame(cm, index=['Bart', 'Lisa'], columns=['Bart pred', 'Lisa pred'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bart has more lines than Lisa, which is how I figured out the ordering of the labels. However, you can also always get them using the `.classes_` attribute of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bart Simpson', 'Lisa Simpson'], dtype='<U12')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate precision and recall. Remember: precision is the proportion of the \"Bart\" predictions that is actually \"Bart\". Recall is the proportion of real \"Bart\" that is predicted as \"Bart\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision for Bart is: 0.6334762275915822\n",
      "The recall for Bart is: 0.782430806257521\n",
      "The precision for Lisa is: 0.6299631600491199\n",
      "The precision for Lisa is: 0.45\n"
     ]
    }
   ],
   "source": [
    "print(f\"The precision for Bart is: {cm.iloc[0,0]/(cm.iloc[0,0]+cm.iloc[1,0])}\")\n",
    "print(f\"The recall for Bart is: {cm.iloc[0,0]/(cm.iloc[0,0]+cm.iloc[0,1])}\")\n",
    "print(f\"The precision for Lisa is: {cm.iloc[1,1]/(cm.iloc[1,1]+cm.iloc[0,1])}\")\n",
    "print(f\"The precision for Lisa is: {cm.iloc[1,1]/(cm.iloc[1,1]+cm.iloc[1,0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do the same much shorter using a built-in function `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Bart Simpson       0.63      0.78      0.70      4155\n",
      "Lisa Simpson       0.63      0.45      0.52      3420\n",
      "\n",
      "    accuracy                           0.63      7575\n",
      "   macro avg       0.63      0.62      0.61      7575\n",
      "weighted avg       0.63      0.63      0.62      7575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_test_p, nb.classes_)) #this function needs the class names, which are in nb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting probabilities instead of classes ##\n",
    "\n",
    "We can predict the probabilities of a line of dialogue using the method `.predict_proba`. Let's try it on a line of dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where's Mr. Bergstrom?\n",
      "[[0.02823148 0.97176852]]\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0,1])\n",
    "print(nb.predict_proba(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us an array/matrix of size 1x2 (you can see this from the double square brackets). Let's check out more lines. We need to get inside the array. Note that the array is two-dimensional (see the brackets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: 0. Where's Mr. Bergstrom?\n",
      "Bart: 0.02823148173303606, Lisa: 0.9717685182669633\n",
      "Line: 1. That life is worth living.\n",
      "Bart: 0.5962751907882123, Lisa: 0.4037248092117888\n",
      "Line: 2. Victory party under the slide!\n",
      "Bart: 0.8162185640113552, Lisa: 0.18378143598864466\n",
      "Line: 3. Mr. Bergstrom! Mr. Bergstrom!\n",
      "Bart: 0.0007086004249150008, Lisa: 0.9992913995750851\n",
      "Line: 4. Do you know where I could find him?\n",
      "Bart: 0.5373212010811312, Lisa: 0.4626787989188686\n",
      "Line: 5. The train, how like him... traditional, yet environmentally sound.\n",
      "Bart: 0.08794218252630742, Lisa: 0.9120578174736946\n",
      "Line: 6. I see he touched you, too.\n",
      "Bart: 0.5219607655971505, Lisa: 0.47803923440285034\n",
      "Line: 7. Hey, thanks for your vote, man.\n",
      "Bart: 0.9547850467242326, Lisa: 0.0452149532757656\n",
      "Line: 8. Well, you got that right. Thanks for your vote, girls.\n",
      "Bart: 0.7793934992698764, Lisa: 0.22060650073012048\n",
      "Line: 9. Well, don't sweat it. Just so long as a couple of people did... right, Milhouse?\n",
      "Bart: 0.8914004903805847, Lisa: 0.10859950961941423\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    prob = nb.predict_proba(X[i])\n",
    "    print(f\"Line: {i}. {df.iloc[i,1]}\")\n",
    "    print(f\"Bart: {prob[0,0]}, Lisa: {prob[0,1]}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to note here that the algorithm might have picked up (for fans of the Simpsons):\n",
    "* Lines 1, 2, 4, 6 provide too little information\n",
    "* Lines 0, 3: Bergstrom is Lisa's substitute teacher\n",
    "* Line 5: might be because of the complex words (and Lisa cares about the environment, too)\n",
    "* Line 7: 'Hey' and especially 'man' make this a very Bart-thing to say.\n",
    "* Line 8: Don't know, maybe 'girls'?\n",
    "* Line 9: Milhouse is Bart's friend (though also in love with Lisa, so it's close)\n",
    "\n",
    "If you want to check out which features predict the classes strongly, see the attribute `feature_log_prob_` of the Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.76409138, -10.16955648, -10.86270367, ...,  -9.25326575,\n",
       "        -10.86270367, -10.86270367],\n",
       "       [-10.77645316, -10.77645316, -10.77645316, ..., -10.77645316,\n",
       "        -10.77645316, -10.77645316]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the most defining words ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.76409138, -10.16955648, -10.86270367, ...,  -9.25326575,\n",
       "        -10.86270367, -10.86270367],\n",
       "       [-10.77645316, -10.77645316, -10.77645316, ..., -10.77645316,\n",
       "        -10.77645316, -10.77645316]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
